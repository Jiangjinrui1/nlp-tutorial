{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "7-FP_Q8vJUtX"
      },
      "outputs": [],
      "source": [
        "# code by Tae Hwan Jung @graykode, modify by wmathor\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optimizer\n",
        "import torch.utils.data as Data\n",
        "\n",
        "dtype = torch.FloatTensor"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "5K5cfsDwP6JQ"
      },
      "outputs": [],
      "source": [
        "sentences = ['i like cat', 'i love coffee', 'i hate milk']\n",
        "sentences_list = \" \".join(sentences).split() # ['i', 'like', 'cat', 'i', 'love'. 'coffee',...]\n",
        "vocab = list(set(sentences_list))\n",
        "word2idx = {w:i for i, w in enumerate(vocab)}\n",
        "idx2word = {i:w for i, w in enumerate(vocab)}\n",
        "\n",
        "V = len(vocab)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "dzkc00uqQiXT"
      },
      "outputs": [],
      "source": [
        "def make_data(sentences):\n",
        "  input_data = []\n",
        "  target_data = []\n",
        "  for sen in sentences:\n",
        "    sen = sen.split() # ['i', 'like', 'cat']\n",
        "    input_tmp = [word2idx[w] for w in sen[:-1]]\n",
        "    target_tmp = word2idx[sen[-1]]\n",
        "\n",
        "    input_data.append(input_tmp)\n",
        "    target_data.append(target_tmp)\n",
        "  return input_data, target_data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "2kBFTErzRMFy"
      },
      "outputs": [],
      "source": [
        "input_data, target_data = make_data(sentences)\n",
        "input_data, target_data = torch.LongTensor(input_data), torch.LongTensor(target_data)\n",
        "dataset = Data.TensorDataset(input_data, target_data)\n",
        "loader = Data.DataLoader(dataset, 2, True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "XlQ46HoTRyxn"
      },
      "outputs": [],
      "source": [
        "# parameters\n",
        "m = 2\n",
        "n_step = 2\n",
        "n_hidden = 10"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "uGURCnXxRav9"
      },
      "outputs": [],
      "source": [
        "class NNLM(nn.Module):\n",
        "  def __init__(self):\n",
        "    super(NNLM, self).__init__()\n",
        "    self.C = nn.Embedding(V, m)\n",
        "    self.H = nn.Parameter(torch.randn(n_step * m, n_hidden).type(dtype))\n",
        "    self.d = nn.Parameter(torch.randn(n_hidden).type(dtype))\n",
        "    self.b = nn.Parameter(torch.randn(V).type(dtype))\n",
        "    self.W = nn.Parameter(torch.randn(n_step * m, V).type(dtype))\n",
        "    self.U = nn.Parameter(torch.randn(n_hidden, V).type(dtype))\n",
        "\n",
        "  def forward(self, X):\n",
        "    '''\n",
        "    X : [batch_size, n_step]\n",
        "    '''\n",
        "    X = self.C(X) # [batch_size, n_step, m]\n",
        "    X = X.view(-1, n_step * m) # [batch_szie, n_step * m]\n",
        "    hidden_out = torch.tanh(self.d + torch.mm(X, self.H)) # [batch_size, n_hidden]\n",
        "    output = self.b + torch.mm(X, self.W) + torch.mm(hidden_out, self.U)\n",
        "    return output\n",
        "model = NNLM()\n",
        "optim = optimizer.Adam(model.parameters(), lr=1e-3)\n",
        "criterion = nn.CrossEntropyLoss()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 101
        },
        "colab_type": "code",
        "id": "dtjKlEU-UP_l",
        "outputId": "759c1167-9a5c-4d1d-d621-2efb0e626454"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1000 0.013112356886267662\n",
            "1000 0.014540893025696278\n",
            "2000 0.0031150239519774914\n",
            "2000 0.0012197205796837807\n",
            "3000 0.0006006562616676092\n",
            "3000 0.0007951673469506204\n",
            "4000 0.0002020362881012261\n",
            "4000 0.00024577934527769685\n",
            "5000 7.271464710356668e-05\n",
            "5000 7.664863369427621e-05\n"
          ]
        }
      ],
      "source": [
        "for epoch in range(5000):\n",
        "  for batch_x, batch_y in loader:\n",
        "    pred = model(batch_x)\n",
        "    loss = criterion(pred, batch_y)\n",
        "\n",
        "    if (epoch + 1) % 1000 == 0:\n",
        "      print(epoch + 1, loss.item())\n",
        "    optim.zero_grad()\n",
        "    loss.backward()\n",
        "    optim.step()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "colab_type": "code",
        "id": "0Mqqhs4-UpaB",
        "outputId": "87c8a8c0-2413-4d78-8818-dc8f25e03682"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['cat', 'coffee', 'milk']\n"
          ]
        }
      ],
      "source": [
        "# Pred\n",
        "# input_data = input_data[:2]\n",
        "pred = model(input_data).max(1, keepdim=True)[1]\n",
        "print([idx2word[idx.item()] for idx in pred.squeeze()])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "smWy_LLvU0sj"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "name": "“NNLM-Torch.ipynb”的副本",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.7"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
